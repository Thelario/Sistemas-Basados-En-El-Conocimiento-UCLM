{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ime2JlxEszKr"
   },
   "source": [
    "<a id=\"c45\"></a>\n",
    "# <font color=\"#004D7F\"> Implementación del C4.5</font>\n",
    "\n",
    "En este apartado vamos a explicar la segunda parte de vuestro trabajo con los árboles de decisión: la implementación del C4.5.\n",
    "\n",
    "Como hemos visto antes, la implementación de `scikit-learn` no tiene en cuenta las variables categóricas o discretas. Por eso, nosotros vamos a hacer una implementación del C4.5 que tenga en cuenta tanto las variables categóricas como las continuas. \n",
    "\n",
    "Esta implementación va a consistir en una versión simplificada del algoritmo. Al tratarse de un problema de clasificación, utilizaremos la entropía (en vez de Gini) para calcular la ganancia y no será obligatorio realizar la poda. Si será obligatorio implementar, por lo menos, el hiperparámetro de profundida máxima. La implementación del Gini, así como la poda o cualquier otro hiperparámetro como el `min_samples_leaf` visto en `scikit-learn` serán partes opcionales de la práctica.\n",
    "\n",
    "Vamos a seguir la estructura de los algoritmos de SciKit, por lo que deberemos implementar una clase `C45` que herede de `BaseEstimator` y que tenga las funciones `__init__`,  `fit` y `predict`. Al final se deberá comparar el comportamiento del algoritmo implementado con los resultados obtenidos de la versión de `scikit-learn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import copy\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import graphviz \n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Location</th>\n",
       "      <th>MinTemp</th>\n",
       "      <th>MaxTemp</th>\n",
       "      <th>Rainfall</th>\n",
       "      <th>Evaporation</th>\n",
       "      <th>Sunshine</th>\n",
       "      <th>WindGustDir</th>\n",
       "      <th>WindGustSpeed</th>\n",
       "      <th>WindDir9am</th>\n",
       "      <th>...</th>\n",
       "      <th>Humidity9am</th>\n",
       "      <th>Humidity3pm</th>\n",
       "      <th>Pressure9am</th>\n",
       "      <th>Pressure3pm</th>\n",
       "      <th>Cloud9am</th>\n",
       "      <th>Cloud3pm</th>\n",
       "      <th>Temp9am</th>\n",
       "      <th>Temp3pm</th>\n",
       "      <th>RainToday</th>\n",
       "      <th>RainTomorrow</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2008-12-01</td>\n",
       "      <td>Albury</td>\n",
       "      <td>13.4</td>\n",
       "      <td>22.9</td>\n",
       "      <td>0.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>44.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>71.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1007.7</td>\n",
       "      <td>1007.1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.9</td>\n",
       "      <td>21.8</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2008-12-02</td>\n",
       "      <td>Albury</td>\n",
       "      <td>7.4</td>\n",
       "      <td>25.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WNW</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NNW</td>\n",
       "      <td>...</td>\n",
       "      <td>44.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1010.6</td>\n",
       "      <td>1007.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2</td>\n",
       "      <td>24.3</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2008-12-03</td>\n",
       "      <td>Albury</td>\n",
       "      <td>12.9</td>\n",
       "      <td>25.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>WSW</td>\n",
       "      <td>46.0</td>\n",
       "      <td>W</td>\n",
       "      <td>...</td>\n",
       "      <td>38.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1007.6</td>\n",
       "      <td>1008.7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>23.2</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2008-12-04</td>\n",
       "      <td>Albury</td>\n",
       "      <td>9.2</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NE</td>\n",
       "      <td>24.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>45.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1017.6</td>\n",
       "      <td>1012.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.1</td>\n",
       "      <td>26.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2008-12-05</td>\n",
       "      <td>Albury</td>\n",
       "      <td>17.5</td>\n",
       "      <td>32.3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>W</td>\n",
       "      <td>41.0</td>\n",
       "      <td>ENE</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1010.8</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>29.7</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145455</th>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>2.8</td>\n",
       "      <td>23.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E</td>\n",
       "      <td>31.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1024.6</td>\n",
       "      <td>1020.3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.1</td>\n",
       "      <td>22.4</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145456</th>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>3.6</td>\n",
       "      <td>25.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NNW</td>\n",
       "      <td>22.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>56.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1023.5</td>\n",
       "      <td>1019.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.9</td>\n",
       "      <td>24.5</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145457</th>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>5.4</td>\n",
       "      <td>26.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>N</td>\n",
       "      <td>37.0</td>\n",
       "      <td>SE</td>\n",
       "      <td>...</td>\n",
       "      <td>53.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>1016.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.5</td>\n",
       "      <td>26.1</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145458</th>\n",
       "      <td>2017-06-24</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>7.8</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SE</td>\n",
       "      <td>28.0</td>\n",
       "      <td>SSE</td>\n",
       "      <td>...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1019.4</td>\n",
       "      <td>1016.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145459</th>\n",
       "      <td>2017-06-25</td>\n",
       "      <td>Uluru</td>\n",
       "      <td>14.9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ESE</td>\n",
       "      <td>...</td>\n",
       "      <td>62.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1020.2</td>\n",
       "      <td>1017.9</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>No</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>145460 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Date Location  MinTemp  MaxTemp  Rainfall  Evaporation  \\\n",
       "0       2008-12-01   Albury     13.4     22.9       0.6          NaN   \n",
       "1       2008-12-02   Albury      7.4     25.1       0.0          NaN   \n",
       "2       2008-12-03   Albury     12.9     25.7       0.0          NaN   \n",
       "3       2008-12-04   Albury      9.2     28.0       0.0          NaN   \n",
       "4       2008-12-05   Albury     17.5     32.3       1.0          NaN   \n",
       "...            ...      ...      ...      ...       ...          ...   \n",
       "145455  2017-06-21    Uluru      2.8     23.4       0.0          NaN   \n",
       "145456  2017-06-22    Uluru      3.6     25.3       0.0          NaN   \n",
       "145457  2017-06-23    Uluru      5.4     26.9       0.0          NaN   \n",
       "145458  2017-06-24    Uluru      7.8     27.0       0.0          NaN   \n",
       "145459  2017-06-25    Uluru     14.9      NaN       0.0          NaN   \n",
       "\n",
       "        Sunshine WindGustDir  WindGustSpeed WindDir9am  ... Humidity9am  \\\n",
       "0            NaN           W           44.0          W  ...        71.0   \n",
       "1            NaN         WNW           44.0        NNW  ...        44.0   \n",
       "2            NaN         WSW           46.0          W  ...        38.0   \n",
       "3            NaN          NE           24.0         SE  ...        45.0   \n",
       "4            NaN           W           41.0        ENE  ...        82.0   \n",
       "...          ...         ...            ...        ...  ...         ...   \n",
       "145455       NaN           E           31.0         SE  ...        51.0   \n",
       "145456       NaN         NNW           22.0         SE  ...        56.0   \n",
       "145457       NaN           N           37.0         SE  ...        53.0   \n",
       "145458       NaN          SE           28.0        SSE  ...        51.0   \n",
       "145459       NaN         NaN            NaN        ESE  ...        62.0   \n",
       "\n",
       "        Humidity3pm  Pressure9am  Pressure3pm  Cloud9am  Cloud3pm  Temp9am  \\\n",
       "0              22.0       1007.7       1007.1       8.0       NaN     16.9   \n",
       "1              25.0       1010.6       1007.8       NaN       NaN     17.2   \n",
       "2              30.0       1007.6       1008.7       NaN       2.0     21.0   \n",
       "3              16.0       1017.6       1012.8       NaN       NaN     18.1   \n",
       "4              33.0       1010.8       1006.0       7.0       8.0     17.8   \n",
       "...             ...          ...          ...       ...       ...      ...   \n",
       "145455         24.0       1024.6       1020.3       NaN       NaN     10.1   \n",
       "145456         21.0       1023.5       1019.1       NaN       NaN     10.9   \n",
       "145457         24.0       1021.0       1016.8       NaN       NaN     12.5   \n",
       "145458         24.0       1019.4       1016.5       3.0       2.0     15.1   \n",
       "145459         36.0       1020.2       1017.9       8.0       8.0     15.0   \n",
       "\n",
       "        Temp3pm  RainToday  RainTomorrow  \n",
       "0          21.8         No            No  \n",
       "1          24.3         No            No  \n",
       "2          23.2         No            No  \n",
       "3          26.5         No            No  \n",
       "4          29.7         No            No  \n",
       "...         ...        ...           ...  \n",
       "145455     22.4         No            No  \n",
       "145456     24.5         No            No  \n",
       "145457     26.1         No            No  \n",
       "145458     26.0         No            No  \n",
       "145459     20.9         No           NaN  \n",
       "\n",
       "[145460 rows x 23 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rain = pd.read_csv('weatherAUS.csv')\n",
    "df_rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables continuas\n",
    "df_rain['MinTemp'] = df_rain['MinTemp'].fillna(df_rain['MinTemp'].mean())\n",
    "df_rain['MaxTemp'] = df_rain['MaxTemp'].fillna(df_rain['MaxTemp'].mean())\n",
    "df_rain['Rainfall'] = df_rain['Rainfall'].fillna(df_rain['Rainfall'].mean())\n",
    "df_rain['WindGustSpeed'] = df_rain['WindGustSpeed'].fillna(df_rain['WindGustSpeed'].mean())\n",
    "df_rain['WindSpeed9am'] = df_rain['WindSpeed9am'].fillna(df_rain['WindSpeed9am'].mean())\n",
    "df_rain['WindSpeed3pm'] = df_rain['WindSpeed3pm'].fillna(df_rain['WindSpeed3pm'].mean())\n",
    "df_rain['Humidity9am'] = df_rain['Humidity9am'].fillna(df_rain['Humidity9am'].mean())\n",
    "df_rain['Humidity3pm'] = df_rain['Humidity3pm'].fillna(df_rain['Humidity3pm'].mean())\n",
    "df_rain['Pressure9am'] = df_rain['Pressure9am'].fillna(df_rain['Pressure9am'].mean())\n",
    "df_rain['Pressure3pm'] = df_rain['Pressure3pm'].fillna(df_rain['Pressure3pm'].mean())\n",
    "df_rain['Cloud9am'] = df_rain['Cloud9am'].fillna(df_rain['Cloud9am'].mean())\n",
    "df_rain['Cloud3pm'] = df_rain['Cloud3pm'].fillna(df_rain['Cloud3pm'].mean())\n",
    "df_rain['Temp9am'] = df_rain['Temp9am'].fillna(df_rain['Temp9am'].mean())\n",
    "df_rain['Temp3pm'] = df_rain['Temp3pm'].fillna(df_rain['Temp3pm'].mean())\n",
    "\n",
    "# Variables categóricas\n",
    "df_rain['Location'].replace(np.nan, 'Canberra', inplace=True)\n",
    "df_rain['WindGustDir'].replace(np.nan, 'W', inplace=True)\n",
    "df_rain['WindDir9am'].replace(np.nan, 'N', inplace=True)\n",
    "df_rain['WindDir3pm'].replace(np.nan, 'SE', inplace=True)\n",
    "df_rain['RainToday'].replace(np.nan, 'No', inplace=True)\n",
    "df_rain['RainTomorrow'].replace(np.nan, 'No', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nencoder = LabelEncoder()\\ndf_rain['RainTomorrow'] = encoder.fit_transform(df_rain['RainTomorrow'])\\ndf_rain['Location'] = encoder.fit_transform(df_rain['Location'])\\ndf_rain['WindGustDir'] = encoder.fit_transform(df_rain['WindGustDir'])\\ndf_rain['WindDir9am'] = encoder.fit_transform(df_rain['WindDir9am'])\\ndf_rain['WindDir3pm'] = encoder.fit_transform(df_rain['WindDir3pm'])\\ndf_rain['RainToday'] = encoder.fit_transform(df_rain['RainToday'])\\n\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "encoder = LabelEncoder()\n",
    "df_rain['RainTomorrow'] = encoder.fit_transform(df_rain['RainTomorrow'])\n",
    "df_rain['Location'] = encoder.fit_transform(df_rain['Location'])\n",
    "df_rain['WindGustDir'] = encoder.fit_transform(df_rain['WindGustDir'])\n",
    "df_rain['WindDir9am'] = encoder.fit_transform(df_rain['WindDir9am'])\n",
    "df_rain['WindDir3pm'] = encoder.fit_transform(df_rain['WindDir3pm'])\n",
    "df_rain['RainToday'] = encoder.fit_transform(df_rain['RainToday'])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = df_rain.columns\n",
    "attributes = features[1:-1]  \n",
    "target = features[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_rain[attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df_rain[target] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "HV3WFusYe6JG"
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "# Ejemplo de la estructura básica de un algoritmo que hereda de BaseEstimator siguiendo la estructura de SciKit\n",
    "class C45(BaseEstimator):\n",
    "    # constructor\n",
    "    def __init__(self):\n",
    "        return\n",
    "\n",
    "    # siguiendo las guias de scikit-learn disponibles en https://scikit-learn.org/stable/developers/develop.html,\n",
    "    # creamos las funciones fit para el entrenamiento\n",
    "    def fit(self, X, y):\n",
    "        return\n",
    "        \n",
    "    # y predict para las predicciones de casos nuevos\n",
    "    def predict(self, X):\n",
    "        return\n",
    "    \n",
    "    # tambien se da una funcion score que deberá calcular el accuracy\n",
    "    def score(self, X, y):\n",
    "        return\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XlOMRoJ1fa08"
   },
   "source": [
    "Sabemos que la forma de trabajar con SciKit puede ser algo restrictiva. Por eso, a continuación os dejamos un esqueleto del árbol de decisión, para que os podáis centrar en el algoritmo y no en los detalles técnicos de SciKit o python. \n",
    "\n",
    "Esto es totalmente opcional, el que se encuentre más cómodo programando el algoritmo desde 0 es libre de hacerlo, mientras los resultados sean correctos y por lo menos se mantenga la estructura del `BaseEstimator`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7AR4m1Cr26qk"
   },
   "outputs": [],
   "source": [
    "class Tree_c45:\n",
    "    def __init__(self):\n",
    "        # primero indicamos si el objeto es hoja o raiz\n",
    "        self.is_leaf = True\n",
    "        \n",
    "        # atributos para el corte cuando el objeto es una raiz\n",
    "        # indicamos el indice de la variable de corte y los valores\n",
    "        self.var_index = -1\n",
    "        self.cut_value = 0\n",
    "        # los hijos deben ser objetos de Tree_c45\n",
    "        self.list_of_childs = []\n",
    "        \n",
    "        # atributos cuando el Tree_c45 es una hoja\n",
    "        # indicamos el valor de la clase y en class_count una tupla (casos con ese valor, casos totales en la hoja)\n",
    "        self.class_value = -1\n",
    "        self.class_count = 0\n",
    "        self.valorRegresion = \"\"\n",
    "        \n",
    "        # para el nivel de profundidad en el arbol de la raiz o la hoja\n",
    "        self.level = -1\n",
    "        \n",
    "    def __str__(self):\n",
    "        output = ''\n",
    "        if(self.is_leaf):\n",
    "            if(self.valorRegresion == \"\"):\n",
    "                output += 'Class value: ' + str(self.class_value) + '\\tCounts: ' + str(self.class_count)\n",
    "            else:\n",
    "                output += self.valorRegresion\n",
    "        else:\n",
    "            output += 'Feature '+ str(self.var_index)\n",
    "            for i in range(len(self.list_of_childs)):\n",
    "                output += '\\n'+'\\t'*(self.level+1)+str(self.cut_value)+': '+str(self.list_of_childs[i])\n",
    "            \n",
    "        return output\n",
    "    \n",
    "    # esta funcion nos servira para hacer predicciones y debe ser completada\n",
    "    def predict(self,x):\n",
    "\n",
    "        if (self.is_leaf == True):\n",
    "\n",
    "            return self.class_value\n",
    "\n",
    "        else:\n",
    "\n",
    "            columna = self.var_index\n",
    "            valorDeColumna = x[columna].unique()[0]\n",
    "\n",
    "            if(isinstance(valorDeColumna, str)):\n",
    "\n",
    "                if (valorDeColumna == self.cut_value):\n",
    "                    hijoExpandir = self.list_of_childs[0]\n",
    "\n",
    "                else:\n",
    "                    hijoExpandir = self.list_of_childs[1]\n",
    "\n",
    "            else:\n",
    "                if (valorDeColumna <= self.cut_value):\n",
    "                    hijoExpandir = self.list_of_childs[0]\n",
    "\n",
    "                else:\n",
    "                    hijoExpandir = self.list_of_childs[1]  \n",
    "\n",
    "            return hijoExpandir.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ya que en esta entrega teníamos que calcular tanto el `GINI` como la `entropía` para la ganancia de información, necesitamos tener dos métodos para cada uno. El primero calcula el `GINI` o la `entropía` con `dataframes`, y el segundo asume que vas a pasarle un array de `numPy`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def giniConDataframes(y):\n",
    "    \n",
    "        if len(y.value_counts()) == 1:\n",
    "            return 0\n",
    "\n",
    "        a = y.value_counts()[0]\n",
    "        b = y.value_counts()[1]\n",
    "\n",
    "        total = a + b\n",
    "\n",
    "        gini = 1 - ((pow((a / total), 2)) + (pow((b / total), 2)))\n",
    "\n",
    "        return gini\n",
    "\n",
    "def entropiaConDataframes(y):\n",
    "    \n",
    "        if len(y.value_counts()) == 1:\n",
    "            return 0\n",
    "\n",
    "        total = y.value_counts()[0] + y.value_counts()[1]\n",
    "\n",
    "        entropia = (-y.value_counts()[0] / total * np.log2(y.value_counts()[0] / total)) + (-y.value_counts()[1] / total * np.log2(y.value_counts()[1] / total))\n",
    "\n",
    "        return entropia\n",
    "\n",
    "def entropiaConNumPy(y, useEncoder):\n",
    "   \n",
    "        if useEncoder:\n",
    "            a = len(y[y == 0.0])\n",
    "            b = len(y[y == 1.0])\n",
    "        else:\n",
    "            a = len(y[y == 'No'])\n",
    "            b = len(y[y == 'Yes'])\n",
    "\n",
    "        if a == 0 or b == 0:\n",
    "            return 0\n",
    "\n",
    "        total = a + b\n",
    "\n",
    "        entropia = (-a/ total * np.log2(a / total)) + (-b / total * np.log2(b / total))\n",
    "\n",
    "        return entropia\n",
    "\n",
    "def gini(y, useEncoder):\n",
    "\n",
    "    if useEncoder:\n",
    "        a = len(y[y == 0.0])\n",
    "        b = len(y[y == 1.0])\n",
    "    else:\n",
    "        a = len(y[y == 'No'])\n",
    "        b = len(y[y == 'Yes'])\n",
    "\n",
    "    if a == 0 or b == 0:\n",
    "        return 0\n",
    "\n",
    "    total = a + b\n",
    "\n",
    "    aux =  1 - ((pow((a / total), 2)) + (pow((b / total), 2)))\n",
    "\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "pJk9Rcc37L9Y"
   },
   "outputs": [],
   "source": [
    "from scipy.stats import entropy\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class C45(BaseEstimator):\n",
    "    # constructor con la profundidad del arbol, que por defecto es 2 y donde inicializamos el arbol que vamos a aprender\n",
    "    def __init__(self, max_depth=2):\n",
    "        self.max_depth = max_depth\n",
    "        self.tree = Tree_c45()\n",
    "        self.metodo = 1 # el tipo de metodo, gini o entropia, 1 para entropia 2 para gini\n",
    "        self.maxRamificacion = {}\n",
    "        self.limiteRamificacion = 1\n",
    "        self.useEncoder = False\n",
    "        self.columnToEncode = 'RainTomorrow'\n",
    "        self.regresion = False\n",
    "        \n",
    "    # siguiendo las guias de scikit-learn, creamos las funciones fit para el entrenamiento\n",
    "    def fit(self, X, y):\n",
    "\n",
    "        for columna in X:\n",
    "            self.maxRamificacion[columna] = 0\n",
    "\n",
    "        if self.useEncoder:\n",
    "            encoder = LabelEncoder()\n",
    "            df_rain[self.columnToEncode] = encoder.fit_transform(df_rain[self.columnToEncode])\n",
    "            features = df_rain.columns\n",
    "            target = features[-1]\n",
    "            y = df_rain[target] \n",
    "\n",
    "        # esta será la llamada a la funcion recursiva que aprendera el arbol a partir de los datos\n",
    "        self.make_cut(X, y, self.tree, 0)\n",
    "        \n",
    "    # y predict para las predicciones de casos nuevos\n",
    "    def predict(self, X):\n",
    "        return np.array([self.tree.predict(x) for x in X])\n",
    "    \n",
    "    # tambien se da una funcion score que calcula el accuracy\n",
    "    def score(self, X, y):\n",
    "        return np.sum(self.predict(X)==y)/y.shape[0]\n",
    "    \n",
    "    # esta es la funcion principal, encargada de encontrar la variable y su punto de corte que maximice la ganancia en base a la entropia.\n",
    "    # se basa en que los cortes se van a realizar sobre variables continuas aunque la salida sea discreta\n",
    "    def make_cut(self, X, y, current_tree, current_depth):\n",
    "\n",
    "        # esqueleto con la funcionalidad basica\n",
    "\n",
    "        # antes de realizar ninguna operacion comprobamos si hemos alcanzado el limite del arbol,\n",
    "        # si es asi, actualizamos el arbol ya que estamos en un nodo hoja \n",
    "        # y no hace falta buscar variable ni continuar con las llamadas recursivas\n",
    "        \n",
    "        if current_depth >= self.max_depth:\n",
    "            current_tree.is_leaf = True # Al haber superado la profundidad maxima, es una hoja, por lo que vamos a ver los datos que tiene.\n",
    "            a = y.value_counts()[0]\n",
    "            b = y.value_counts()[1]\n",
    "            if(a > b):\n",
    "                current_tree.class_value = 0 # Sacamos el valor de la variable que mas se repita\n",
    "                current_tree.class_count = a # Sacamos la cantidad del valor que mas se ha repetido\n",
    "                if (self.regresion == True):\n",
    "                    valor0 = 1 - a / (a + b)\n",
    "                    current_tree.valorRegresion = (\"Valor Regresion = \" + str(valor0))\n",
    "            else:\n",
    "                current_tree.class_value = 1 # Sacamos el valor de la variable que mas se repita\n",
    "                current_tree.class_count = b # Sacamos la cantidad del valor que mas se ha repetido\n",
    "                if (self.regresion == True):\n",
    "                    valor1 = b / (a + b)\n",
    "                    current_tree.valorRegresion = (\"Valor Regresion = \" + str(valor1))\n",
    "            return\n",
    "\n",
    "        # Primero, obtenemos la entropia de la clase\n",
    "        if self.metodo == 1:\n",
    "            mejorValor = entropiaConDataframes(y)\n",
    "        else:\n",
    "            mejorValor = giniConDataframes(y)\n",
    "        \n",
    "        # Segundo, deberemos recorrer todas las caracteristicas siguiendo estos pasos\n",
    "        mejorColumna = \"MinTemp\"\n",
    "        puntoCorte = 0\n",
    "        gananciaMax = 0\n",
    "\n",
    "        # Para cada columna en las variables predictoras:\n",
    "        for columna in X:\n",
    "\n",
    "            # 1. Ordenar los valores de la caracteristica y aplicar a la clase\n",
    "            aux = pd.DataFrame([X[columna], y])\n",
    "            aux = aux.transpose()\n",
    "            aux = aux.sort_values(by = columna)\n",
    "\n",
    "            # 2. Obtener los puntos de corte en base a la clase ordenada\n",
    "            puntosCorte = aux[columna].unique()\n",
    "            puntosCorte = np.array(puntosCorte)\n",
    "\n",
    "            debug = False\n",
    "            if debug:\n",
    "                print(puntosCorte)\n",
    "\n",
    "            # Pasamos a numpy el dataframe\n",
    "            aux = aux.to_numpy()\n",
    "            predictora = []\n",
    "            objetivo = []\n",
    "\n",
    "            for n in range(0, len(aux)):\n",
    "                objetivo.append(aux[n][1])\n",
    "                predictora.append(aux[n][0])\n",
    "\n",
    "            objetivo = np.array(objetivo)\n",
    "            predictora = np.array(predictora)\n",
    "\n",
    "            debug = False\n",
    "            if debug:\n",
    "                print(objetivo)\n",
    "                print(predictora)\n",
    "\n",
    "            previous = []\n",
    "            longitud = len(objetivo)\n",
    "            mejora = False\n",
    "\n",
    "            # 3. Para cada corte, calculamos la entropia\n",
    "            for punto in puntosCorte:\n",
    "\n",
    "                previous = predictora[predictora < punto]\n",
    "                \n",
    "                lenPrevious = len(previous)\n",
    "\n",
    "                objPrev = objetivo[:lenPrevious]\n",
    "                objNext = objetivo[lenPrevious:]\n",
    "\n",
    "                if self.metodo == 1:\n",
    "                    valor1 = entropiaConNumPy(objPrev, self.useEncoder)\n",
    "                    valor2 = entropiaConNumPy(objNext, self.useEncoder)\n",
    "                else:\n",
    "                    valor1 = gini(objPrev, self.useEncoder)\n",
    "                    valor2 = gini(objNext, self.useEncoder)\n",
    "\n",
    "                    if debug:\n",
    "                        print(str(valor1))\n",
    "                        print(str(valor2) + \"\\n\")\n",
    "\n",
    "                total = valor1 * (lenPrevious / longitud) + valor2 * ((longitud - lenPrevious) / longitud)\n",
    "\n",
    "                debug = False\n",
    "                if debug:\n",
    "                    print(\"Valor 1: \" + str(valor1))\n",
    "                    print(\"Valor 2: \" + str(valor2))\n",
    "                    print(\"Total: \" + str(total))\n",
    "\n",
    "                # 4. Calculamos la ganancia con la entropia obtenida y la de la clase\n",
    "                if self.metodo == 1:\n",
    "                    gananciaInfo = mejorValor - total\n",
    "\n",
    "                    # 5. Almacenamos la variable y el punto de corte con mayor ganancia             \n",
    "                    if gananciaInfo > gananciaMax:\n",
    "\n",
    "                        gananciaMax = gananciaInfo\n",
    "                        mejora = True\n",
    "                        mejorValor = total\n",
    "                        puntoCorte = punto\n",
    "                        mejorColumna = columna\n",
    "\n",
    "                        # Calculamos las dos particiones que se van a hacer en la base de datos\n",
    "                        g1 = X[X[columna] <= punto]\n",
    "                        g2 = X[X[columna] > punto]\n",
    "\n",
    "                        gMejor = [g1, g2]\n",
    "                else:\n",
    "\n",
    "                    # Almacenamos la variable y el punto de corte con mayor ganancia\n",
    "                    if total < mejorValor:\n",
    "\n",
    "                        mejorValor = total;\n",
    "                        mejora = True\n",
    "                        puntoCorte = punto\n",
    "                        mejorColumna = columna\n",
    "\n",
    "                        # Calculamos las dos particiones que se van a hacer en la base de datos\n",
    "                        g1 = X[X[columna] <= punto]\n",
    "                        g2 = X[X[columna] > punto]\n",
    "\n",
    "                        gMejor = [g1, g2]\n",
    "\n",
    "            debug = False\n",
    "            if mejora and debug:\n",
    "                print(\"Columna: \" + str(columna)) \n",
    "                print(\"Mejor entorpia: \" + str(mejorValor))\n",
    "                print(\"Punto de corte: \" + str(puntoCorte))  \n",
    "                print(\"\")\n",
    "\n",
    "        debug = False\n",
    "        if debug:\n",
    "            print(\"Ramificar por columna: \" + str(mejorColumna))\n",
    "            print(\"Mejor entropia: \" + str(mejorValor))\n",
    "            print(\"Punto de corte: \" + str(puntoCorte))\n",
    "        \n",
    "        # Antes de llamar a la funcion recursiva hay que actualizar los valores del arbol\n",
    "        if debug:\n",
    "            print(\"Antes\")\n",
    "            print(gMejor[0])\n",
    "        \n",
    "        if(isinstance(gMejor[0][mejorColumna].iloc[0], str)):\n",
    "            gMejor[0] = gMejor[0].drop(mejorColumna, axis=1)\n",
    "            gMejor[1] = gMejor[1].drop(mejorColumna, axis=1)\n",
    "\n",
    "        if debug:\n",
    "            print(\"Despues\")\n",
    "            print(gMejor[0])\n",
    "        \n",
    "        if (self.maxRamificacion[mejorColumna] < self.limiteRamificacion - 1):\n",
    "            self.maxRamificacion[mejorColumna] = self.maxRamificacion[mejorColumna] + 1\n",
    "        elif mejorColumna in gMejor[0]:\n",
    "                gMejor[0] = gMejor[0].drop(mejorColumna, axis=1)\n",
    "                gMejor[1] = gMejor[1].drop(mejorColumna, axis=1)\n",
    "        \n",
    "        tree1 = Tree_c45()\n",
    "        tree2 = Tree_c45()\n",
    "\n",
    "        current_tree.is_leaf = False\n",
    "        current_tree.level = current_depth\n",
    "        current_tree.var_index = mejorColumna\n",
    "        current_tree.cut_value = puntoCorte\n",
    "        current_tree.list_of_childs = [tree1, tree2]\n",
    "\n",
    "        # para continuar con el algoritmo hay que hacer una llamada a la funcion\n",
    "        # de forma recursiva para cada hijo\n",
    "        for i in range (len(current_tree.list_of_childs)):\n",
    "            self.make_cut(gMejor[i], y.loc[gMejor[i].index], current_tree.list_of_childs[i], current_tree.level+1)\n",
    "        \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXivs2IrwO_Y"
   },
   "source": [
    "El algoritmo debe implementar por lo menos un hiperparámetro `max_depth` como condición de parada. Seguid el ejemplo mostrado en la función `__init__` del código.\n",
    "\n",
    "Para comprobar que funciona correctamente, creamos un objeto  que entrenamos con `fit` y del que obtenemos una tasa de aciertos con `score`. Subiremos ejemplos de la salida del algoritmo al campus virtual para que podáis comprobar vuestra implementación.\n",
    "\n",
    "Para finalizar, hay que comparar los resultados obtenidos por nuestra implementación frente a la implementación de `scikit-learn`. También habrá que comparar que variables son más importantes ahora y obtener las gráficas correspondientes. Este estudio no tiene que ser tan exhaustivo como el de la primera sección.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrega & Pruebas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las dos primeras ejecuciones del algoritmo que queremos hacer son para un árbol de profundidad 1 usando el método `GINI` para el cálculo de la ganancia de información. Lo importante que tenemos que tener en cuenta en estas dos ejecuciones es que hemos implementado `dos formas distintas` de tratar la `variable objetivo` dentro del árbol. La primera es tratándola como variable `categórica` ('Yes' y 'No') y la segunda como variable `continua` (1 y 0). Esto lo hemos hecho porque el algoritmo es bastante `más eficiente` tratanto números que tratando strings, y se puede comprobar en los distintos tiempos que toman los algoritmos. El tiempo del mismo árbol usando el `encoder` y no usándolo es de 41.5s y de 1m 36.4s, respectivamente. Por lo tanto, hemos decidido usar el encoder en todas las pruebas. Aun usando el encoder, el algoritmo solo codifica la variable objetivo, y no las variables predictoras, por lo que en las variables predictoras estamos trabajando con variables categóricas y continuas, como se pide en el enunciado de la práctica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t72.0: Class value: 0\tCounts: 105152\n",
      "\t72.0: Class value: 1\tCounts: 13889\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 1\n",
    "arbol.metodo = 2            # GINI\n",
    "arbol.useEncoder = True     # Variable objetivo con 0s y 1s\n",
    "arbol.regresion = False\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t72.0: Class value: 0\tCounts: 105152\n",
      "\t72.0: Class value: 0\tCounts: 13889\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 1\n",
    "arbol.metodo = 2            # GINI\n",
    "arbol.useEncoder = False    # Variable objetivo con 'No' y 'Yes'\n",
    "arbol.regresion = False\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La `regresión` se trata de predecir un valor numérico en función de sus variables predictoras. La estructura generadad del árbol es igual pero en las hojas, en vez de tener una variable, tenemos un valor numérico. En nuestro caso este valor numérico rondará entre cero y uno, suponiendo 0 cuando no va a llover y 1 cuando sí va a llover. En base a esto podemos tomar la probabilidad de lluvia o no lluvia del valor numérico de la hoja. Este valor numérico se obtiene haciendo la media según el punton de corte en la hoja. Las dos celdas siguientes muestran dos ejemplos, el primero con `GINI` y `regresión` activada, y el segundo con `entropía` y `regresión` activada. La regresión nos permite ver de forma más sencilla el poder predecir si mañana va a llover o no. En la primera celda, tenemos que ramificando por `Humidity3pm`, en una hoja tenemos una probabilidad de que llueva del 0.146 y en la otra hoja una probabilidad de que llueva del 0.622."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t72.0: Valor Regresion = 0.14607763521195383\n",
      "\t72.0: Valor Regresion = 0.6222670250896057\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 1\n",
    "arbol.metodo = 2            # GINI\n",
    "arbol.useEncoder = True     # Variable objetivo con 0s y 1s\n",
    "arbol.regresion = True\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t60.0: Feature Rainfall\n",
      "\t\t0.1: Valor Regresion = 0.08077221790746703\n",
      "\t\t0.1: Valor Regresion = 0.1855168386217637\n",
      "\t60.0: Feature Rainfall\n",
      "\t\t0.1: Valor Regresion = 0.3116082161710134\n",
      "\t\t0.1: Valor Regresion = 0.5370383348517765\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 2\n",
    "arbol.metodo = 1            # Entropía\n",
    "arbol.useEncoder = True     # Variable objetivo con 0 y 1\n",
    "arbol.regresion = True\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora vamos a calcular los mismos árboles que hemos calculado anteriormente pero en vez de usar `GINI` para calcular la ganancia de información, esta vez vamos a usar la `entropía`. Para ello diferenciamos esto usando la variable `metodo`, en la que si toma el valor de `2` usaría GINI y si toma el valor de `1` usaría la entropía."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar en las dos siguientes ejecuciones del algoritmo C45, usando la ganancia de entropía obtenemos que también vamos a partir el árbol por la misma variable predictora `Humidity3pm`, pero en este caso el punto de corte no es el mismo que usando `GINI`. En las ejecuciones anteriores vemos que el punto de corte era `72.0`, mientras que ahora es `60.0`. También podemos ver que usando el encoder la ejecución va mucho más rápida, como hemos visto en las dos ejecuciones anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t60.0: Class value: 0\tCounts: 87200\n",
      "\t60.0: Class value: 0\tCounts: 26383\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 1\n",
    "arbol.metodo = 1            # Entropía\n",
    "arbol.useEncoder = True     # Variable objetivo con 0 y 1\n",
    "arbol.regresion = False\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t60.0: Class value: 0\tCounts: 87200\n",
      "\t60.0: Class value: 0\tCounts: 26383\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 1\n",
    "arbol.metodo = 1            # Entropía\n",
    "arbol.useEncoder = False    # Variable objetivo con 'No' y 'Yes'\n",
    "arbol.regresion = False\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez hemos explicado como hemos implementado las distintas funciones del algoritmo y las diferencias que hay, vamos a hacer ejecuciones pero esta vez con más profundidad en el árbol, para ver qué partición hace esta vez."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente árbol usamos el `encoder` para acelerar la ejecución y establecemos la `profundidad` del árbol en `2`. El árbol incialmente hace una partición por `Humidity3pm` en el punto de corte de `60.0`, y en cada partición hace otra división por `Rainfall`, con punto de corte igual a `0.1`. Es importante comentar que el método de `ganancia de información` que estamos usando es la `entropía`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t60.0: Feature Rainfall\n",
      "\t\t0.1: Class value: 0\tCounts: 66280\n",
      "\t\t0.1: Class value: 0\tCounts: 20920\n",
      "\t60.0: Feature Rainfall\n",
      "\t\t0.1: Class value: 0\tCounts: 13171\n",
      "\t\t0.1: Class value: 1\tCounts: 15326\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 2\n",
    "arbol.metodo = 1            # Entropía\n",
    "arbol.useEncoder = True     # Variable objetivo con 0 y 1\n",
    "arbol.regresion = False\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si en vez de profundidad `2` establecemos profundidad `3` vemos como las particiones iniciales son las mismas que el árbol anterior, pero luego divide por `Sunshine` y `WindGustSpeed` en la izquierda y por `Cloud3pm` y `WindGustSpeed` por la derecha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t60.0: Feature Rainfall\n",
      "\t\t0.1: Feature Sunshine\n",
      "\t\t\t7.4: Class value: 0\tCounts: 6486\n",
      "\t\t\t7.4: Class value: 0\tCounts: 29190\n",
      "\t\t0.1: Feature WindGustSpeed\n",
      "\t\t\t40.03523007167319: Class value: 0\tCounts: 12039\n",
      "\t\t\t40.03523007167319: Class value: 0\tCounts: 8881\n",
      "\t60.0: Feature Rainfall\n",
      "\t\t0.1: Feature Cloud3pm\n",
      "\t\t\t7.0: Class value: 0\tCounts: 11721\n",
      "\t\t\t7.0: Class value: 1\tCounts: 1610\n",
      "\t\t0.1: Feature WindGustSpeed\n",
      "\t\t\t41.0: Class value: 0\tCounts: 9294\n",
      "\t\t\t41.0: Class value: 1\tCounts: 8006\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 3\n",
    "arbol.metodo = 1            # Entropía\n",
    "arbol.useEncoder = True     # Variable objetivo con 0 y 1\n",
    "arbol.regresion = False\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por último, vamos a ver un árbol de profundidad 3 usando la regresión."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Humidity3pm\n",
      "\t60.0: Feature Rainfall\n",
      "\t\t0.1: Feature Sunshine\n",
      "\t\t\t7.4: Valor Regresion = 0.20989158240955053\n",
      "\t\t\t7.4: Valor Regresion = 0.04828665514655539\n",
      "\t\t0.1: Feature WindGustSpeed\n",
      "\t\t\t40.03523007167319: Valor Regresion = 0.12887120115774242\n",
      "\t\t\t40.03523007167319: Valor Regresion = 0.25149599662874\n",
      "\t60.0: Feature Rainfall\n",
      "\t\t0.1: Feature Cloud3pm\n",
      "\t\t\t7.0: Valor Regresion = 0.27076463634666836\n",
      "\t\t\t7.0: Valor Regresion = 0.5261437908496732\n",
      "\t\t0.1: Feature WindGustSpeed\n",
      "\t\t\t41.0: Valor Regresion = 0.44059227157818703\n",
      "\t\t\t41.0: Valor Regresion = 0.6714189869171419\n"
     ]
    }
   ],
   "source": [
    "arbol = C45()\n",
    "arbol.max_depth = 3\n",
    "arbol.metodo = 1            # Entropía\n",
    "arbol.useEncoder = True     # Variable objetivo con 0 y 1\n",
    "arbol.regresion = True\n",
    "arbol.fit(X,y)\n",
    "print(arbol.tree)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Practica 1 - Arboles de decision.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "37e99736b63964a131a8a93f686c5d5d523443a6a32dc86aaafffdd1077ded46"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
